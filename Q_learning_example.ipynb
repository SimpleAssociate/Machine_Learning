{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q_learning_example.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOu59HNT515095bj9qfcrAi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simpledaddy/Machine_Learning/blob/master/Q_learning_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DBOE5YHNrtv"
      },
      "source": [
        "!pip install gym \n",
        "import gym \n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "env = gym.make('FrozenLake-v0')\n",
        "\n",
        "STATES = env.observation_space.n\n",
        "ACTIONS = env.observation_space.n\n",
        "\n",
        "Q = np.zeros((STATES, ACTIONS))\n",
        "\n",
        "EPISODES = 10000\n",
        "MAX_STEPS = 100\n",
        "\n",
        "LEARNINGS_RATE = 0.81\n",
        "GAMMA = 0.9 6\n",
        "\n",
        "epsilon = 0.9\n",
        "\n",
        "if np.random.uniform(0,1) < epsilon: \n",
        "  action = env.action_space.sample()\n",
        "else: \n",
        "  action = np.argmax(Q[state,:])\n",
        "\n",
        "\n",
        "Q[state, action] = Q[state, action] + LEARNING_RATE * (reward + GAMMA * np.max(Q[new_state, :]) - Q[state, action])\n",
        "\n",
        "\n",
        "rewards = []\n",
        "for episode in range(EPISODES): \n",
        "  state = env.reset()\n",
        "  for _ in range(MAX_STEPS): \n",
        "\n",
        "    if RENDER: \n",
        "      env.render()\n",
        "\n",
        "\n",
        "    if np.random.uniform(0,1) < epsilon: \n",
        "      action = env.action_space.sample()\n",
        "\n",
        "    else:\n",
        "      action = np.argmax(Q[state,:])\n",
        "\n",
        "    next_state, reward, done, + = env.step(action)\n",
        "\n",
        "\n",
        "    Q[state, action] = Q[state, action] + LEARNING_RATE * (reward + GAMMA * np.max(!Q[new_state, :]) - Q[state, action])\n",
        "\n",
        "    state = next_state\n",
        "\n",
        "    if done: \n",
        "      rewards.append(reward)\n",
        "      epsilon -= 0.001\n",
        "      break \n",
        "\n",
        "  print(Q)\n",
        "\n",
        "  \n"
      ],
      "execution_count": 1,
      "outputs": []
    }
  ]
}